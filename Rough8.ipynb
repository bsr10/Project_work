{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <span style=\"color:RoyalBlue\"> [MATH2319] Course Project - Group 68 </span>\n\n\n\n### <span style=\"color:Crimson\"> Tushar Kondvilkar (s3800119)\n\n### <span style=\"color:Crimson\"> M. Abdullah Anis (s3790720)\n\n### <span style=\"color:Crimson\"> Brian Steven Rathod (s3760875)\n\n</span>\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 1. Introduction"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "When banks give out loans to customers they need to know whether a customer is good credit risk or bad. So the banks do not want to give loan to any customer who is not able to return the loans. Subsequently, they want to give loans to customers who will successfully pay back the loans.\n\nWe have selected a dataset on German Credit Data prepared by Prof. Hoffman which has been imported from the UCI website. The dataset we have chosen propese a classification problem. This dataset contains 1000 rows & 20 attributes. Each row in the dataset represents a customer who has taken credit from the bank. All the potential customers are classified as good or bad credit risk based on many parameters such as credit history. The original dataset has been referenced below. \nThe target feature is 'risk' which contains 2 classes 'Good' or 'Bad' which are represented by 1 & 0 respectively. The target feature classifies whether the customer has good credit risk or bad credit risk.\n\nSource: (UCI Machine Learning Repository: Statlog (German Credit Data) Data Set, 2020) Archive.ics.uci.edu. 2020. UCI Machine Learning Repository: Statlog (German Credit Data) Data Set. [online] <br> </br>\nAvailable at: <https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29> [Accessed 31 May 2020]."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1.1 Objective"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The objective of the study is to use numerous machine learning algorithms in order to find the best model which can classify a customer as good or bad credit risk based on the set of attributes in the dataset."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1.2 Predictive modelling Methodology"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Following are the binary classifiers we considered for classifiying the target feature:\n1. KNN\n2. Decision Tree\n3. Naive Bayes\n4. Random Forest\n5. Logistic Regression\n\nFirst we checked for missing values, encoded categorical features, encoded the target feature and scaled the descriptive features. After that, we split the full dataset to training & test sets with 75:25 ratio. Training dataset contains 750 rows & test dataset has 250 rows.\nNext, we performed feature selection using the powerful Random Forest Importance method inside a pipeline. We selected 15 best features for modelling our data. We set the hyparameter values for all the algorithms & assessed their performance using the training data. Our performance metric was AUC score & we built each model with parallel processing set to -2 cores.\nWe found the tuned classifiers with best hyparameter values using Grid Search. Upon finding the 5 tuned classifiers we fit them on the test data with 10-fold cross validation & performed paired t-tests to check whether any performance difference is statistically significant. Finally we compared classifiers with respect to different scoring metrics such as recall to see which classifier would perform the best."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 2. Data - Preprocessing"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We will be importing all the required librarys below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport io\nimport requests\nfrom sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\nimport sklearn.metrics as metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn import feature_selection as fs\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom numpy.random import randn\nfrom numpy.random import seed\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n#! pip install dython\nfrom dython.nominal import associations\n\n#!pip install --upgrade altair\n#!pip install vega vega_datasets",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.1 Reading Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pd.set_option('display.max_columns', None) \n\nattributeNames = ['checking_account',\n'duration',\n'credit history',\n'purpose',\n'credit amount',\n'savings account',\n'employment status',\n'rate',\n'status_sex',\n'debt',\n'residence',\n'property',\n'age',\n'other installment plans',\n'housing',\n'existing credits',\n'job',\n'liability',\n'telephone',\n'foreign worker',\n'risk']\n\ndf = pd.read_csv(\"Germandata.csv\", \n                   sep = ',', \n                   names = attributeNames)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There were no ID like columns in the dataset."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.head(5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(df.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.2 Types of variable"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": " df.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.3 Checking for Missing Values & Unique values"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.isna().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(df.nunique())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.4 Converting categorical and numerical columns to relevant data types"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat_cols = ['status_sex', 'job', 'housing', 'savings account','checking_account','purpose', 'risk']\nnum_cols = [ 'credit amount', 'duration']\n\ndf[cat_cols] = df[cat_cols].astype(np.object)\ndf[num_cols] = df[num_cols].astype(np.number)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.5 Inserting proper categories to columns"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df[\"checking_account\"].replace({\"A11\": \"0 DM\", \"A12\": \"0 - 200 DM\", \"A13\": \">200 DM\", \"A14\": \"No Checking account\"}, inplace=True)\n\ndf[\"credit history\"].replace({\"A30\": \"no creds taken\", \"A31\": \"all creds paid back\", \"A32\": \"existing creds paid back\", \"A33\": \"delay in paying\",\n                              \"A34\": \"critical account\"}, inplace=True)\n\ndf[\"purpose\"].replace({\"A40\": \"new car\", \"A41\": \"used car\", \"A42\": \"furniture\", \"A43\": \"radio/tv\",\"A44\": \"domestic applicances\",\"A45\": \"repairs\", \n                       \"A46\": \"education\", \"A47\": \"vacation\", \"A48\": \"retraining\", \"A49\": \"business\", \"A410\": \"others\",}, inplace=True)\n\ndf[\"savings account\"].replace({\"A61\": \"<100 DM\", \"A62\": \"100 - 500 DM\", \"A63\": \"500 - 1000 DM\", \"A64\": \">1000 DM\",\"A65\": \"No savings account\"}, inplace=True)\n\ndf[\"employment status\"].replace({\"A71\": \"Unemployed\", \"A72\": \"<1 year\", \"A73\": \"1 - 4 years\", \"A74\": \"4 - 7 years\", \"A75\": \">7 years\"}, inplace=True)\n\ndf[\"status_sex\"].replace({\"A91\": \"M/D\", \"A92\": \"F/D,M\", \"A93\": \"M/S\", \"A94\": \"M/M\", \"A95\": \"F/S\"}, inplace=True)\n\ndf[\"debt\"].replace({\"A101\": \"no debt\", \"A102\": \"co-applicant\", \"A103\": \"guarantor\"}, inplace=True)\n\ndf[\"property\"].replace({\"A121\": \"real estate\", \"A122\": \"life inusrance\", \"A123\": \"car\", \"A124\": \"no property\"}, inplace=True)\n\ndf[\"other installment plans\"].replace({\"A141\": \"bank\", \"A142\": \"stores\", \"A143\": \"none\"}, inplace=True)\n\ndf[\"housing\"].replace({\"A151\": \"rent\", \"A152\": \"own\", \"A153\": \"for free\"}, inplace=True)\n\ndf[\"job\"].replace({\"A171\": \"unemployed\", \"A172\": \"unskilled\", \"A173\": \"skilled\", \"A174\": \"management\"}, inplace=True)\n\ndf[\"telephone\"].replace({\"A191\": \"none\", \"A192\": \"yes\"}, inplace=True)\n\ndf[\"foreign worker\"].replace({\"A201\": \"yes\", \"A202\": \"no\"}, inplace=True)\n\ndf['risk'].replace({1: 'Good', 2: 'Bad'}, inplace= True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.6 Converting Age column to categorical variable"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We converted the continuous age variable into 4 categories -\n\nstudent = 18 to 25 years old \n\nyoung = 26 to 35 years old \n\nadults = 36 to 60 years old\n\nSenior =  > 61 years old"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "interval = (18, 25, 35, 60, 120)\ncats = ['Student', 'Young', 'Adult', 'Senior']\ndf[\"Age_cat\"] = pd.cut(df['age'], interval, labels=cats)\n\n#df = df.drop(columns = 'age') - performed after data visualisation",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Converting remanining categorical columns to proper data type(object)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\ndf[\"rate\"] = df[\"rate\"].astype(np.object)\ndf[\"residence\"] = df[\"residence\"].astype(np.object)\ndf[\"existing credits\"] = df[\"existing credits\"].astype(np.object)\ndf[\"liability\"] = df[\"liability\"].astype(np.object)\ndf[\"risk\"] = df[\"risk\"].astype(np.object)\ndf[\"Age_cat\"] = df[\"Age_cat\"].astype(np.object)\n\ndf.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.7 Summary statistics"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Summary statistics for numeric variables are given below:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Summary statistics for categorical variables are below:"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "df.describe(include = np.object) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 3. Data Visualization"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3.1 Univariate Plots"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ax = df['risk'].value_counts().plot(kind = 'bar')\nax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\nplt.tight_layout()\nplt.title('Figure 1: Bar Chart of Credit Risk', fontsize = 15)\nplt.show();",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We have 700 good credit customers & 300 bad credit customers."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# get a box plot of age\nsns.boxplot(df['age']).set_title('Figure 2: Box Plot of Age', fontsize = 15)\nplt.show();",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The mean age of people applying for credits is around 33 years."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['Age_cat'].value_counts().plot.bar().set_title(\"Number of credits taken by Age category\", fontsize = 15)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The bar graph shows that applications for credit are mostly placed by young people."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['credit amount'].plot(kind='density').set_title(\"Credit amount distribution\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Most credit amount is given to customers is under 5000 Euros."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# histogram of age with kernel density estimate\nsns.distplot(df['age'], kde = True).set_title('Figure 3: Histogram of Age', fontsize = 15)\nplt.show();",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3.2 Bivariate Plots"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.catplot(x=\"Age_cat\", y=\"credit amount\", data=df)\nplt.title(\"Credit amount based on Age category\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The scatter plot shows that most credit amount is taken by adults & young people. Seniors tend to take less credits amount from banks."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Box Plots\nf, (ax) = plt.subplots(1, 1, figsize=(12, 4))\nf.suptitle('Loan duration(in months) by Purpose', fontsize=14)\n\nsns.boxplot(x=\"purpose\", y=\"duration\", data=df,  ax=ax)\nax.set_xlabel(\"Purpose\",size = 12,alpha=0.8)\nax.tick_params(axis='x', labelrotation=35)\nax.set_ylabel(\"Loan duration(in months)\",size = 12,alpha=0.8)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The graph above shows the boxplots of the purposes each client had for taking credit from the bank. We can see that most people get credit froma bank for education, cars and businesses."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.plot.scatter(x='duration',\n                y='credit amount',\n                c='DarkBlue').set_title(\"Plot of credit amount w.r.t duration\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3.3 Multivariate Plots"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "associations(df, theil_u=True, figsize=(15, 15))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The correlation matrix above shows the correlation between each attributes in the dataset."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "f, (ax2) = plt.subplots(1, 1, figsize=(10, 6))\nf.suptitle('Credit Amount - Gender/Status - Foreign Worker', fontsize=14)\n\nsns.violinplot(x=\"status_sex\", y=\"credit amount\", hue=\"foreign worker\", \n               data=df, split=True, inner=\"quart\", linewidth=1.3,\n               ax=ax2)\nax2.set_xlabel(\"Gender and Status\",size = 12,alpha=0.8)\nax2.set_ylabel(\"Credit Amount\",size = 12,alpha=0.8)\nl = plt.legend(loc='upper right', title='Foreign Worker')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Visualizing 3-D mix data using box plots\n# leveraging the concepts of hue and axes for > 1 categorical dimensions\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\nf.suptitle('Purpose - Foreign worker status - Age - Duration (in months)', fontsize=14)\n\nsns.boxplot(x=\"purpose\", y=\"duration\", hue=\"foreign worker\",\n               data=df, ax=ax1)\nax1.set_xlabel(\"Purpose\",size = 12,alpha=0.8)\nax1.tick_params(axis='x', labelrotation=35)\nax1.set_ylabel(\"Duration (in months)\",size = 12,alpha=0.8)\n\nsns.boxplot(x=\"Age_cat\", y=\"duration\", hue=\"foreign worker\",\n               data=df, ax=ax2)\nax2.set_xlabel(\"Age (by category)\",size = 12,alpha=0.8)\nax2.set_ylabel(\"Duration (in months)\",size = 12,alpha=0.8)\nl = plt.legend(loc='best', title='Foreign Worker')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The above plot on the left show the distribution of foreign workers, their purposes of taking credit along with the duration of their credit.\nThe right plot shows the ditribution of foreign workers taking credit w.r.t their age category and  duration of credit."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.barplot(x=df.debt, y=df.duration, hue=df.status_sex,ci=None)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "the graph above shows the debt of each customer w.r.t to the duration of the credit they have taken from the bank. It highlights them based on their status and sex.\n\n\n  Divorced males have the highest rates of debt as guarantors and co-applicants, compared to other gender/status demographics.\n  On the other hand, females in general have lower rates of debt. While single males are likely to have no debt.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.scatterplot(df['credit amount'], df['age'], hue = df['job'])\nplt.title('Figure 8: Scatterplot of credit amount by age coloured by job skill level', fontsize = 15);\nplt.legend(loc = 'upper right',fontsize = 8)\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 8, 5\nplt.show();",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see that skilled people (blue) and people working in management (green) take credits with most credit amount. Also most people under tha age of 65 take credits with amount under 5000 euros."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 4 Encoding Variables"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "converting ordinal variables to category data type"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n\ndf[\"checking_account\"] = df[\"checking_account\"].astype('category')\ndf[\"savings account\"] = df[\"savings account\"].astype('category')\ndf[\"employment status\"] = df[\"employment status\"].astype('category')\ndf[\"credit history\"] = df[\"credit history\"].astype('category')\ndf[\"property\"] = df[\"property\"].astype('category')\ndf[\"other installment plans\"] = df[\"other installment plans\"].astype('category')\n\n#Dropping duplicate age column\ndf = df.drop(columns = 'age')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Label/integer encoding the ordinal variables"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n\ndf[\"checking_account\"] = df[\"checking_account\"].cat.codes\ndf[\"savings account\"] = df[\"savings account\"].cat.codes\ndf[\"employment status\"] = df[\"employment status\"].cat.codes\ndf[\"credit history\"] = df[\"credit history\"].cat.codes\ndf[\"property\"] = df[\"property\"].cat.codes\ndf[\"other installment plans\"] = df[\"other installment plans\"].cat.codes\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 4.1 One-hot encoding (nominal) categorical variables"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n\n# get the list of categorical descriptive features\ncategorical_cols = df.columns[df.dtypes==object].tolist()\n\n# if a categorical descriptive feature has only 2 levels,\n# define only one binary variable\nfor col in categorical_cols:\n    n = len(df[col].unique())\n    if (n == 2):\n        df[col] = pd.get_dummies(df[col], drop_first=True)\n\n# for other categorical features (with > 2 levels), \n# use regular one-hot-encoding \n# if a feature is numeric, it will be untouched\ndf = pd.get_dummies(df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Target variable 'risk' is already integer-encoded in above step as 0 and 1. 0 is 'bad and 1 is 'good'."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\ndata = df.drop(columns = 'risk').values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fdf1 = df.drop(columns = 'risk')\n\nfdf1.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 5. Predictive Modelling"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 5.1 Feature Selection\n\nWe perform feature selection using the powerful random forest importance method inside a pipeline."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\nnum_features = 15\nmodel_rfi = RandomForestClassifier(n_estimators=100)\nmodel_rfi.fit(fdf1, df['risk'])\nfs_indices_rfi = np.argsort(model_rfi.feature_importances_)[::-1][0:num_features]\n\nbest_features_rfi = fdf1.columns[fs_indices_rfi].values\nbest_features_rfi",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "feature_importances_rfi = model_rfi.feature_importances_[fs_indices_rfi]\nfeature_importances_rfi",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_imp = pd.DataFrame({'features': best_features_rfi, \n                       'importances': feature_importances_rfi})\n\ndf_imp",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The above table shows the 15 features we selected along with their importance. Credit amount is the highest as this makes sense as the risk of giving credit is correlated with the amount of the credit given."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "features_df = df[['credit amount', 'checking_account', 'duration', 'credit history',\n       'employment status', 'savings account', 'property', 'rate',\n       'residence', 'other installment plans', 'existing credits',\n       'purpose_new car', 'housing_own', 'Age_cat_Student',\n       'status_sex_M/S','risk']].copy()\n\nfeatures_df.head(5)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 5.2 Train test splitting and data sampling"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We split the full dataset to training & test sets with 75:25 ratio. Training dataset contains 750 rows & test dataset has 250 rows."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split, KFold, cross_val_score # to split the data\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score #To evaluate our model\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Algorithmns models to be compared\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Setting Data and Target variables for modeling and Spliting X and y into train and test versions."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nX = features_df.drop('risk', 1).values\ny = features_df[\"risk\"].values\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, we plot the boxplots for each models according to the scoring metric 'accuracy'. These models are not tuned right now."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# to feed the random state\nseed = 999\n\n# prepare models\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('DT', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('RF', RandomForestClassifier()))\n\n\n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'accuracy'\n\nfor name, model in models:\n        kfold = KFold(n_splits=10, random_state=seed)\n        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(11,6))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "From the above diagram, we can see that LR, NB and RF are performing relatively good in terms of accuracy."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "##### Model Evaluation Strategy"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We will train and tune our models on 750 rows of training data and test them on 250 rows of testing data. we will be employing stratified K fold method to perform cross-validation on the data with number of splits = 5."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n\ncv_method = StratifiedKFold(n_splits=5, random_state=999)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6 Hyper parameter tuning"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 6.1 KNN tuning"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Using Pipeline, we stack feature selection and grid search for KNN hyperparameter tuning via cross-validation. We will use the same Pipeline methodology for NB, DT, RF and LR.\n\nThe hyperparameters for KNN  are as follows:\n\nnumber of neighbors (n_neighbors)\n\nnumber of features (n_features)\n\nthe distance metric p.\n\nFeature selection was done using the powerful Random Forest Importance (RFI) method with 100 estimators. Using the help of a case study referenced at the end, we defined the custom function RFIFeatureSelector() class below to pass in RFI as a step to the pipeline."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.base import BaseEstimator, TransformerMixin\n\n# custom function for RFI feature selection inside a pipeline\n# here we use n_estimators=100\nclass RFIFeatureSelector(BaseEstimator, TransformerMixin):\n    \n    # class constructor \n    # make sure class attributes end with a \"_\"\n    # per scikit-learn convention to avoid errors\n    def __init__(self, n_features_=10):\n        self.n_features_ = n_features_\n        self.fs_indices_ = None\n\n    # override the fit function\n    def fit(self, X, y):\n        from sklearn.ensemble import RandomForestClassifier\n        from numpy import argsort\n        model_rfi = RandomForestClassifier(n_estimators=100)\n        model_rfi.fit(X, y)\n        self.fs_indices_ = argsort(model_rfi.feature_importances_)[::-1][0:self.n_features_] \n        return self \n    \n    # override the transform function\n    def transform(self, X, y=None):\n        return X[:, self.fs_indices_]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Running our KNN classifier to find the best parameters for using grid search cross validation."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\n\npipe_KNN = Pipeline(steps=[('rfi_fs', RFIFeatureSelector()), \n                           ('knn', KNeighborsClassifier())])\n\nparams_pipe_KNN = {'rfi_fs__n_features_': [10, 15, df.shape[1]],\n                   'knn__n_neighbors': [1, 5, 10, 15],\n                   'knn__p': [1, 2]}\n\ngs_pipe_KNN = GridSearchCV(estimator=pipe_KNN, \n                           param_grid=params_pipe_KNN, \n                           cv=cv_method,\n                           refit=True,\n                           n_jobs=-2,\n                           scoring='roc_auc',\n                           verbose=1) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gs_pipe_KNN.fit(X_train, y_train);\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gs_pipe_KNN.best_params_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We found the best parameters for KNN classifier to be:\n    n_neighbours = 10,\n    p = 1 and\n    n_features = 15."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gs_pipe_KNN.best_score_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The best score after cross validation for KNN classifier is 0.59. Let us check the results of other classifiers as this can be improved."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The following function formats grid search results as a pandas data frame so we can see the results for the 5 cross validations. This makes it easier for comparison of different parameter scores."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# custom function to format the search results as a Pandas data frame\ndef get_search_results(gs):\n\n    def model_result(scores, params):\n        scores = {'mean_score': np.mean(scores),\n             'std_score': np.std(scores),\n             'min_score': np.min(scores),\n             'max_score': np.max(scores)}\n        return pd.Series({**params,**scores})\n\n    models = []\n    scores = []\n\n    for i in range(gs.n_splits_):\n        key = f\"split{i}_test_score\"\n        r = gs.cv_results_[key]        \n        scores.append(r.reshape(-1,1))\n\n    all_scores = np.hstack(scores)\n    for p, s in zip(gs.cv_results_['params'], all_scores):\n        models.append((model_result(s, p)))\n\n    pipe_results = pd.concat(models, axis=1).T.sort_values(['mean_score'], ascending=False)\n\n    columns_first = ['mean_score', 'std_score', 'max_score', 'min_score']\n    columns = columns_first + [c for c in pipe_results.columns if c not in columns_first]\n\n    return pipe_results[columns]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "results_KNN = get_search_results(gs_pipe_KNN)\nresults_KNN.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see above that the cross-validated AUC score difference for different hyper parameters is not much. Visualization is shown below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import altair as alt\n\nresults_KNN_10_features = results_KNN[results_KNN['rfi_fs__n_features_'] == 10.0]\n\nalt.Chart(results_KNN_10_features, \n          title='KNN Performance Comparison with 10 Features'\n         ).mark_line(point=True).encode(\n    alt.X('knn__n_neighbors', title='Number of Neighbors'),\n    alt.Y('mean_score', title='AUC Score', scale=alt.Scale(zero=False)),\n    alt.Color('knn__p:N', title='p')\n)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6.2 (Gaussian) Naive Bayes (NB) tuning\n\nAs NB requires every descriptive feature to follow a Gaussian distribution, we performed a power transformation on the input data before fitting the model. We will optomize var_smoothing parameter for NB.\n\nfeature selection was done using RFIFeatureSelector() function."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import PowerTransformer\nData_sample_train_transformed = PowerTransformer().fit_transform(X_train)",
      "execution_count": 230,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import RandomizedSearchCV\n\npipe_NB = Pipeline([('rfi_fs', RFIFeatureSelector()), \n                     ('nb', GaussianNB())])\n\nparams_pipe_NB = {'rfi_fs__n_features_': [10, 15,features_df.shape[1]],\n                  'nb__var_smoothing': np.logspace(1,-3, num=200)}\n\nn_iter_search = 10\ngs_pipe_NB = RandomizedSearchCV(estimator=pipe_NB, \n                          param_distributions=params_pipe_NB, \n                          cv=cv_method,\n                          refit=True,\n                          n_jobs=-2,\n                          scoring='roc_auc',\n                          n_iter=n_iter_search,\n                          verbose=1) \n\ngs_pipe_NB.fit(Data_sample_train_transformed , y_train);",
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=-2)]: Done  50 out of  50 | elapsed:   16.8s finished\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gs_pipe_NB.best_params_",
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 232,
          "data": {
            "text/plain": "{'rfi_fs__n_features_': 16, 'nb__var_smoothing': 0.001320088400831418}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We found the best parameters for NB to be: n_fetaures  = 15 and var_smoothing = 0.0028995"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gs_pipe_NB.best_score_\n",
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 233,
          "data": {
            "text/plain": "0.7548871370175719"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Best score by NB with auc score is 0.74 which is much better than KNN classifier. We shall test more classifiers to see if there is any better one."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "results_NB = get_search_results(gs_pipe_NB)\nresults_NB.head()",
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 234,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_score</th>\n      <th>std_score</th>\n      <th>max_score</th>\n      <th>min_score</th>\n      <th>rfi_fs__n_features_</th>\n      <th>nb__var_smoothing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.754940</td>\n      <td>0.032821</td>\n      <td>0.792340</td>\n      <td>0.708489</td>\n      <td>16.0</td>\n      <td>0.001320</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.754862</td>\n      <td>0.032993</td>\n      <td>0.792094</td>\n      <td>0.707867</td>\n      <td>15.0</td>\n      <td>0.008026</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.754814</td>\n      <td>0.032946</td>\n      <td>0.792340</td>\n      <td>0.708075</td>\n      <td>15.0</td>\n      <td>0.002643</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.754199</td>\n      <td>0.032749</td>\n      <td>0.792735</td>\n      <td>0.707867</td>\n      <td>15.0</td>\n      <td>0.058728</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.754199</td>\n      <td>0.032749</td>\n      <td>0.792735</td>\n      <td>0.707867</td>\n      <td>16.0</td>\n      <td>0.058728</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   mean_score  std_score  max_score  min_score  rfi_fs__n_features_  \\\n1    0.754940   0.032821   0.792340   0.708489                 16.0   \n8    0.754862   0.032993   0.792094   0.707867                 15.0   \n6    0.754814   0.032946   0.792340   0.708075                 15.0   \n5    0.754199   0.032749   0.792735   0.707867                 15.0   \n7    0.754199   0.032749   0.792735   0.707867                 16.0   \n\n   nb__var_smoothing  \n1           0.001320  \n8           0.008026  \n6           0.002643  \n5           0.058728  \n7           0.058728  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see above that the cross-validated AUC score difference for different hyper parameters for NB is small. Visualization is shown below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "results_NB_10_features = results_NB[results_NB['rfi_fs__n_features_'] == 10.0]\n\nalt.Chart(results_NB_10_features, \n          title='NB Performance Comparison with 10 Features'\n         ).mark_line(point=True).encode(\n    alt.X('nb__var_smoothing', title='Var. Smoothing'),\n    alt.Y('mean_score', title='AUC Score', scale=alt.Scale(zero=False))\n)",
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 235,
          "data": {
            "text/plain": "alt.Chart(...)",
            "text/html": "\n<div id=\"altair-viz-b72cbb1db7154bd09496bb71cf4fe2a8\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-b72cbb1db7154bd09496bb71cf4fe2a8\") {\n      outputDiv = document.getElementById(\"altair-viz-b72cbb1db7154bd09496bb71cf4fe2a8\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-bd1ba15fb638450b1b5e5f3e65e1e065\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"nb__var_smoothing\", \"title\": \"Var. Smoothing\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"mean_score\", \"scale\": {\"zero\": false}, \"title\": \"AUC Score\"}}, \"title\": \"NB Performance Comparison with 10 Features\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-bd1ba15fb638450b1b5e5f3e65e1e065\": [{\"mean_score\": 0.70116486170834, \"std_score\": 0.029260434807023873, \"max_score\": 0.7438923395445135, \"min_score\": 0.6542443064182195, \"rfi_fs__n_features_\": 10.0, \"nb__var_smoothing\": 4.99450511585514}]}}, {\"mode\": \"vega-lite\"});\n</script>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6.3 Decision Trees (DT) tuning\nThe hyper parameters for DT are:\n\nmaximum depth (max_depth)\n\nminimum sample split (min_samples_split)\n\nnumber of features (n_features)."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\n\npipe_DT = Pipeline([('rfi_fs', RFIFeatureSelector()),\n                    ('dt', DecisionTreeClassifier(criterion='gini', random_state=999))])\n\nparams_pipe_DT = {'rfi_fs__n_features_': [10],\n                  'dt__max_depth': [5, 10, 15],\n                  'dt__min_samples_split': [5, 50, 100, 150]}\n\ngs_pipe_DT = GridSearchCV(estimator=pipe_DT, \n                          param_grid=params_pipe_DT, \n                          cv=cv_method,\n                          refit=True,\n                          n_jobs=-2,\n                          scoring='roc_auc',\n                          verbose=1) \n\ngs_pipe_DT.fit(X_train, y_train);",
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=-2)]: Done  60 out of  60 | elapsed:   18.7s finished\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gs_pipe_DT.best_params_",
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 237,
          "data": {
            "text/plain": "{'dt__max_depth': 5, 'dt__min_samples_split': 100, 'rfi_fs__n_features_': 10}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "best parameters for Decision tree classifier are:\n'dt__max_depth': 10, 'dt__min_samples_split': 150, 'rfi_fs__n_features_': 10"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gs_pipe_DT.best_score_",
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 238,
          "data": {
            "text/plain": "0.725225379129727"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Deicision Tree classifier after Cross validation with AUC scoring metric gives the best score of 0.718 which is better than KNN but does not beat NB classifier accuracy. We will continue to check for more classifiers. Visulaization of DT classifier is shown below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "results_DT = get_search_results(gs_pipe_DT)\n\nresults_DT_10_features = results_DT[results_DT['rfi_fs__n_features_'] == 10.0]\n\nalt.Chart(results_DT_10_features, \n          title='DT Performance Comparison with 10 Features'\n         ).mark_line(point=True).encode(\n    alt.X('dt__min_samples_split', title='Min Samples for Split'),\n    alt.Y('mean_score', title='AUC Score', scale=alt.Scale(zero=False)),\n    alt.Color('dt__max_depth:N', title='Max Depth')\n)",
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 239,
          "data": {
            "text/plain": "alt.Chart(...)",
            "text/html": "\n<div id=\"altair-viz-3ac7f5bce06640358b553f9868e87cd9\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-3ac7f5bce06640358b553f9868e87cd9\") {\n      outputDiv = document.getElementById(\"altair-viz-3ac7f5bce06640358b553f9868e87cd9\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-391800ca9400aa6a038f253bcc9d5145\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"dt__max_depth\", \"title\": \"Max Depth\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"dt__min_samples_split\", \"title\": \"Min Samples for Split\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"mean_score\", \"scale\": {\"zero\": false}, \"title\": \"AUC Score\"}}, \"title\": \"DT Performance Comparison with 10 Features\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-391800ca9400aa6a038f253bcc9d5145\": [{\"mean_score\": 0.7252656341243299, \"std_score\": 0.026788139146561574, \"max_score\": 0.7561076604554866, \"min_score\": 0.6922031772575251, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 100.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.7219990577055795, \"std_score\": 0.034763366861011946, \"max_score\": 0.7668737060041407, \"min_score\": 0.6658385093167701, \"dt__max_depth\": 10.0, \"dt__min_samples_split\": 150.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.7185361920688008, \"std_score\": 0.030883788025731187, \"max_score\": 0.7504140786749482, \"min_score\": 0.6658385093167701, \"dt__max_depth\": 15.0, \"dt__min_samples_split\": 150.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.7161034798534798, \"std_score\": 0.036207042472865936, \"max_score\": 0.7668737060041407, \"min_score\": 0.6658385093167701, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 150.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.7134485985029463, \"std_score\": 0.030566537827645835, \"max_score\": 0.7566239316239316, \"min_score\": 0.6754807692307693, \"dt__max_depth\": 15.0, \"dt__min_samples_split\": 100.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.7130388995062908, \"std_score\": 0.02476379872181894, \"max_score\": 0.7414529914529916, \"min_score\": 0.6754807692307693, \"dt__max_depth\": 10.0, \"dt__min_samples_split\": 100.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.71043657429527, \"std_score\": 0.015935814791635652, \"max_score\": 0.7392094017094017, \"min_score\": 0.6908902691511388, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 50.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.6972833386420343, \"std_score\": 0.0353945427664768, \"max_score\": 0.7513888888888889, \"min_score\": 0.6420359531772575, \"dt__max_depth\": 10.0, \"dt__min_samples_split\": 50.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.6879986860965122, \"std_score\": 0.028610237582108997, \"max_score\": 0.7354037267080745, \"min_score\": 0.6509316770186335, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.6796643573817487, \"std_score\": 0.03511790084623607, \"max_score\": 0.7175213675213675, \"min_score\": 0.6320910973084886, \"dt__max_depth\": 15.0, \"dt__min_samples_split\": 50.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.6229502442002441, \"std_score\": 0.020937183506520515, \"max_score\": 0.6481366459627329, \"min_score\": 0.5893162393162392, \"dt__max_depth\": 10.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.6087509290226683, \"std_score\": 0.03226958259961737, \"max_score\": 0.6710144927536232, \"min_score\": 0.5847826086956521, \"dt__max_depth\": 15.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 10.0}]}}, {\"mode\": \"vega-lite\"});\n</script>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "results_DT = get_search_results(gs_pipe_DT)\nresults_DT.head()",
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 240,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_score</th>\n      <th>std_score</th>\n      <th>max_score</th>\n      <th>min_score</th>\n      <th>dt__max_depth</th>\n      <th>dt__min_samples_split</th>\n      <th>rfi_fs__n_features_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.725266</td>\n      <td>0.026788</td>\n      <td>0.756108</td>\n      <td>0.692203</td>\n      <td>5.0</td>\n      <td>100.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.721999</td>\n      <td>0.034763</td>\n      <td>0.766874</td>\n      <td>0.665839</td>\n      <td>10.0</td>\n      <td>150.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.718536</td>\n      <td>0.030884</td>\n      <td>0.750414</td>\n      <td>0.665839</td>\n      <td>15.0</td>\n      <td>150.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.716103</td>\n      <td>0.036207</td>\n      <td>0.766874</td>\n      <td>0.665839</td>\n      <td>5.0</td>\n      <td>150.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.713449</td>\n      <td>0.030567</td>\n      <td>0.756624</td>\n      <td>0.675481</td>\n      <td>15.0</td>\n      <td>100.0</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    mean_score  std_score  max_score  min_score  dt__max_depth  \\\n2     0.725266   0.026788   0.756108   0.692203            5.0   \n7     0.721999   0.034763   0.766874   0.665839           10.0   \n11    0.718536   0.030884   0.750414   0.665839           15.0   \n3     0.716103   0.036207   0.766874   0.665839            5.0   \n10    0.713449   0.030567   0.756624   0.675481           15.0   \n\n    dt__min_samples_split  rfi_fs__n_features_  \n2                   100.0                 10.0  \n7                   150.0                 10.0  \n11                  150.0                 10.0  \n3                   150.0                 10.0  \n10                  100.0                 10.0  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6.4 Random Forest tuning\n\nThe Hyper parameters for Random forest are:\n\nmax_depth\n\nnumber of estimators (n_estimators)\n\nmax_features\n\nn_features\n\nAs before, we will use RFI to select features and perform grid search cross validation to find the best parameters for the decision tree classifier."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n\npipe_RF = Pipeline([('rfi_fs', RFIFeatureSelector()),\n                    ('rf', RandomForestClassifier( random_state=999))])\n\nparams_pipe_RF = {'rf__max_depth': [3,5, 7, 10, None],\n              'rf__n_estimators':[3,5,10,25,50,150],\n              'rf__max_features': [4,7,15],\n                 'rfi_fs__n_features_': [15]}\n\ngs_pipe_RF = GridSearchCV(estimator=pipe_RF, \n                          param_grid=params_pipe_RF, \n                          cv=cv_method,\n                          refit=True,\n                          n_jobs=-2,\n                          scoring='roc_auc',\n                          verbose=1) \n\ngs_pipe_RF.fit(X_train, y_train);",
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=-2)]: Done 450 out of 450 | elapsed:  3.8min finished\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gs_pipe_RF.best_params_",
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 242,
          "data": {
            "text/plain": "{'rf__max_depth': 7,\n 'rf__max_features': 4,\n 'rf__n_estimators': 50,\n 'rfi_fs__n_features_': 15}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "best parameters for random forest classifier are :  \n 'max_depth': 10,\n 'max_features': 4,\n 'n_estimators': 50,\n 'n_features_': 15"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gs_pipe_RF.best_score_",
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 243,
          "data": {
            "text/plain": "0.7791526923961707"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### RF classifier after Cross validation with AUC scoring metric gives the best score of 0.769 which is better than all classifiers tested before.\nVisualization of  Random forest classifier with best parameters is shown below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "results_RF = get_search_results(gs_pipe_DT)\n\nresults_RF_10_features = results_DT[results_RF['rfi_fs__n_features_'] == 10.0]\n\nalt.Chart(results_RF_10_features, \n          title='RF Performance Comparison with 10 Features'\n         ).mark_line(point=True).encode(\n    alt.X('dt__min_samples_split', title='Min Samples for Split'),\n    alt.Y('mean_score', title='AUC Score', scale=alt.Scale(zero=False)),\n    alt.Color('dt__max_depth:N', title='Max Depth')\n)",
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 244,
          "data": {
            "text/plain": "alt.Chart(...)",
            "text/html": "\n<div id=\"altair-viz-367c6cc261924ef487092189a1f9e427\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-367c6cc261924ef487092189a1f9e427\") {\n      outputDiv = document.getElementById(\"altair-viz-367c6cc261924ef487092189a1f9e427\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-391800ca9400aa6a038f253bcc9d5145\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"dt__max_depth\", \"title\": \"Max Depth\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"dt__min_samples_split\", \"title\": \"Min Samples for Split\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"mean_score\", \"scale\": {\"zero\": false}, \"title\": \"AUC Score\"}}, \"title\": \"RF Performance Comparison with 10 Features\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-391800ca9400aa6a038f253bcc9d5145\": [{\"mean_score\": 0.7252656341243299, \"std_score\": 0.026788139146561574, \"max_score\": 0.7561076604554866, \"min_score\": 0.6922031772575251, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 100.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.7219990577055795, \"std_score\": 0.034763366861011946, \"max_score\": 0.7668737060041407, \"min_score\": 0.6658385093167701, \"dt__max_depth\": 10.0, \"dt__min_samples_split\": 150.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.7185361920688008, \"std_score\": 0.030883788025731187, \"max_score\": 0.7504140786749482, \"min_score\": 0.6658385093167701, \"dt__max_depth\": 15.0, \"dt__min_samples_split\": 150.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.7161034798534798, \"std_score\": 0.036207042472865936, \"max_score\": 0.7668737060041407, \"min_score\": 0.6658385093167701, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 150.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.7134485985029463, \"std_score\": 0.030566537827645835, \"max_score\": 0.7566239316239316, \"min_score\": 0.6754807692307693, \"dt__max_depth\": 15.0, \"dt__min_samples_split\": 100.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.7130388995062908, \"std_score\": 0.02476379872181894, \"max_score\": 0.7414529914529916, \"min_score\": 0.6754807692307693, \"dt__max_depth\": 10.0, \"dt__min_samples_split\": 100.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.71043657429527, \"std_score\": 0.015935814791635652, \"max_score\": 0.7392094017094017, \"min_score\": 0.6908902691511388, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 50.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.6972833386420343, \"std_score\": 0.0353945427664768, \"max_score\": 0.7513888888888889, \"min_score\": 0.6420359531772575, \"dt__max_depth\": 10.0, \"dt__min_samples_split\": 50.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.6879986860965122, \"std_score\": 0.028610237582108997, \"max_score\": 0.7354037267080745, \"min_score\": 0.6509316770186335, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.6796643573817487, \"std_score\": 0.03511790084623607, \"max_score\": 0.7175213675213675, \"min_score\": 0.6320910973084886, \"dt__max_depth\": 15.0, \"dt__min_samples_split\": 50.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.6229502442002441, \"std_score\": 0.020937183506520515, \"max_score\": 0.6481366459627329, \"min_score\": 0.5893162393162392, \"dt__max_depth\": 10.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 10.0}, {\"mean_score\": 0.6087509290226683, \"std_score\": 0.03226958259961737, \"max_score\": 0.6710144927536232, \"min_score\": 0.5847826086956521, \"dt__max_depth\": 15.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 10.0}]}}, {\"mode\": \"vega-lite\"});\n</script>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 6.5 Logistic Regression tuning\n\nHyper paramter for Logistic regression is C which is the inverse of regularization strength.\n\nWe performed Grid search cross validation to find the best paramters for Logistic regression."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "LR = GridSearchCV(cv=None,\n             estimator=LogisticRegression(C=1.0, intercept_scaling=1,   \n               dual=False, fit_intercept=True, penalty='l2', tol=0.0001),scoring='roc_auc',\n             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]})",
      "execution_count": 245,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "LR.fit(X_train, y_train)",
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 246,
          "data": {
            "text/plain": "GridSearchCV(cv=None, error_score='raise-deprecating',\n       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False),\n       fit_params=None, iid='warn', n_jobs=None,\n       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n       scoring='roc_auc', verbose=0)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "LR.best_params_",
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 247,
          "data": {
            "text/plain": "{'C': 1}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The best parameter for LR is c = 0.1. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "LR.best_score_",
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 248,
          "data": {
            "text/plain": "0.7401441822948176"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We found the best score for LR to be 0.72 which is better than KNN but fails to beat random forest in terms of accuracy with AUC scoring metric"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 7. Performance Comparison between Models\n\nBefore, we found the hyper parameters for our classifiers using 750 rows of training data using cross validation. In order for us to really compare their performance, we will use the best parameters of each classifier (tuned) to predict using 250 rows of Test data which is unseen data for the classifiers. The scoring metric will be AUC. We will perform 10 splits and use the mean of the results for each split to determine the accuracy of each classifier on the Test data. The seed value for each classifier is same ie 999.\n\nFinally, we will perform paired t-test on the results of each classifier to compare whether the differences are statistically significant. The comparison of each tuned classifier will be with every other tuned classifier being tested."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let see usee the KNN model performance using cross validation."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import cross_val_score\n\ncv_method_ttest = StratifiedKFold(n_splits=10, random_state=999)\n\ncv_results_KNN = cross_val_score(estimator=gs_pipe_KNN.best_estimator_,\n                                 X=X_test,\n                                 y=y_test, \n                                 cv=cv_method_ttest, \n                                 n_jobs=-2,\n                                 scoring='roc_auc')\ncv_results_KNN.mean()",
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 249,
          "data": {
            "text/plain": "0.5981763538748833"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Mean result for KNN performance on test data is 0.597 which is not that good."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "NB model performance using cross validation:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Data_sample_test_transformed = PowerTransformer().fit_transform(X_test)\n\ncv_results_NB = cross_val_score(estimator=gs_pipe_NB.best_estimator_,\n                                X=Data_sample_test_transformed,\n                                y=y_test, \n                                cv=cv_method_ttest, \n                                n_jobs=-2,\n                                scoring='roc_auc')\ncv_results_NB.mean()",
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 250,
          "data": {
            "text/plain": "0.7346580298786181"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Mean result for NB performance on test data is 0.718 which is better than KNN."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "DT model performance using cross validation."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cv_results_DT = cross_val_score(estimator=gs_pipe_DT.best_estimator_,\n                                X=X_test,\n                                y=y_test, \n                                cv=cv_method_ttest, \n                                n_jobs=-2,\n                                scoring='roc_auc')\ncv_results_DT.mean()",
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 251,
          "data": {
            "text/plain": "0.6852211718020542"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Mean result for DT performance on test data is 0.665 which is better than KNN but not as good as NB."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Random forest model performance using cross validation."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cv_results_RF = cross_val_score(estimator=gs_pipe_RF.best_estimator_,\n                                X=X_test,\n                                y=y_test, \n                                cv=cv_method_ttest, \n                                n_jobs=-2,\n                                scoring='roc_auc')\ncv_results_RF.mean()",
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 252,
          "data": {
            "text/plain": "0.7630077030812326"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Mean result for RF performance on test data after Cross validation is 0.792 which is quite good and better than all previois."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Logistic Regression model performance using cross validation."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cv_results_LR = cross_val_score(estimator=LR.best_estimator_,\n                                X=X_test,\n                                y=y_test, \n                                cv=cv_method_ttest, \n                                n_jobs=-2,\n                                scoring='roc_auc')\ncv_results_LR.mean()",
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 253,
          "data": {
            "text/plain": "0.7031921101774044"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Mean result for LR performance on test data using CV is 0.709 which is not as good as that of RF."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Let us now go ahead and perform the paired t-test between all 5 classifiers to see which difference is statistically significant between them."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from scipy import stats\n\nprint(stats.ttest_rel(cv_results_KNN, cv_results_NB))\nprint(stats.ttest_rel(cv_results_KNN, cv_results_RF))\nprint(stats.ttest_rel(cv_results_KNN, cv_results_LR))\nprint(stats.ttest_rel(cv_results_DT, cv_results_KNN))\nprint(stats.ttest_rel(cv_results_DT, cv_results_NB))\nprint(stats.ttest_rel(cv_results_DT, cv_results_RF))\nprint(stats.ttest_rel(cv_results_KNN, cv_results_LR))\nprint(stats.ttest_rel(cv_results_LR, cv_results_NB))\nprint(stats.ttest_rel(cv_results_RF, cv_results_LR))\nprint(stats.ttest_rel(cv_results_RF, cv_results_NB))\n",
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Ttest_relResult(statistic=-2.6495205221227485, pvalue=0.026497014608065254)\nTtest_relResult(statistic=-3.2951242717008173, pvalue=0.009301975375724131)\nTtest_relResult(statistic=-2.399363263956133, pvalue=0.03993956073053389)\nTtest_relResult(statistic=1.4520118228491787, pvalue=0.18045039886680117)\nTtest_relResult(statistic=-1.722497575429051, pvalue=0.11907834861066367)\nTtest_relResult(statistic=-3.67740045469032, pvalue=0.005095978889629742)\nTtest_relResult(statistic=-2.399363263956133, pvalue=0.03993956073053389)\nTtest_relResult(statistic=-1.873049963927677, pvalue=0.0938410868120229)\nTtest_relResult(statistic=3.5631044330531436, pvalue=0.006089609402280024)\nTtest_relResult(statistic=1.3679793483111935, pvalue=0.20449879174845403)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "From the results above, we can safely say that with a 95% significance level, Random forest classifier (RF) is statistically the best model in terms of AUC when compared to the test data. A p-value smaller than 0.05 indicates a statistically significant difference. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "Now we shall consider the following scoring metrics to evaluate models based on the test set:\n\nAccuracy\nPrecision\nRecall\nF1 Score (the harmonic average of precision and recall)\nConfusion Matrix\nThese metrics can be computed using classification_report from sklearn.metrics. The classification reports are shown below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pred_KNN = gs_pipe_KNN.predict(X_test)",
      "execution_count": 255,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Data_test_transformed = PowerTransformer().fit_transform(X_test)\npred_NB = gs_pipe_NB.predict(Data_test_transformed)",
      "execution_count": 256,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pred_DT = gs_pipe_DT.predict(X_test)",
      "execution_count": 257,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pred_RF = gs_pipe_RF.predict(X_test)",
      "execution_count": 258,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pred_LR = LR.predict(X_test)",
      "execution_count": 259,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import metrics\nprint(\"\\nClassification report for K-Nearest Neighbor\") \nprint(metrics.classification_report(y_test, pred_KNN))\nprint(\"\\nClassification report for Naive Bayes\") \nprint(metrics.classification_report(y_test, pred_NB))\nprint(\"\\nClassification report for Decision Tree\") \nprint(metrics.classification_report(y_test, pred_DT))\nprint(\"\\nClassification report for Random Forest\") \nprint(metrics.classification_report(y_test, pred_RF))\nprint(\"\\nClassification report for Logistic Regression\") \nprint(metrics.classification_report(y_test, pred_LR))",
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nClassification report for K-Nearest Neighbor\n              precision    recall  f1-score   support\n\n           0       0.29      0.17      0.21        72\n           1       0.71      0.84      0.77       178\n\n   micro avg       0.64      0.64      0.64       250\n   macro avg       0.50      0.50      0.49       250\nweighted avg       0.59      0.64      0.61       250\n\n\nClassification report for Naive Bayes\n              precision    recall  f1-score   support\n\n           0       0.48      0.43      0.46        72\n           1       0.78      0.81      0.80       178\n\n   micro avg       0.70      0.70      0.70       250\n   macro avg       0.63      0.62      0.63       250\nweighted avg       0.69      0.70      0.70       250\n\n\nClassification report for Decision Tree\n              precision    recall  f1-score   support\n\n           0       0.60      0.44      0.51        72\n           1       0.80      0.88      0.84       178\n\n   micro avg       0.76      0.76      0.76       250\n   macro avg       0.70      0.66      0.67       250\nweighted avg       0.74      0.76      0.74       250\n\n\nClassification report for Random Forest\n              precision    recall  f1-score   support\n\n           0       0.68      0.38      0.48        72\n           1       0.79      0.93      0.85       178\n\n   micro avg       0.77      0.77      0.77       250\n   macro avg       0.73      0.65      0.67       250\nweighted avg       0.75      0.77      0.74       250\n\n\nClassification report for Logistic Regression\n              precision    recall  f1-score   support\n\n           0       0.53      0.33      0.41        72\n           1       0.77      0.88      0.82       178\n\n   micro avg       0.72      0.72      0.72       250\n   macro avg       0.65      0.61      0.62       250\nweighted avg       0.70      0.72      0.70       250\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import metrics\nprint(\"\\nConfusion matrix for K-Nearest Neighbor\") \nprint(metrics.confusion_matrix(y_test, pred_KNN))\nprint(\"\\nConfusion matrix for Naive Bayes\") \nprint(metrics.confusion_matrix(y_test, pred_NB))\nprint(\"\\nConfusion matrix for Decision Tree\") \nprint(metrics.confusion_matrix(y_test, pred_DT))\nprint(\"\\nConfusion matrix for Random Forest\") \nprint(metrics.confusion_matrix(y_test, pred_RF))\nprint(\"\\nConfusion matrix for Logistic Regression\") \nprint(metrics.confusion_matrix(y_test, pred_LR))",
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nConfusion matrix for K-Nearest Neighbor\n[[ 12  60]\n [ 29 149]]\n\nConfusion matrix for Naive Bayes\n[[ 31  41]\n [ 33 145]]\n\nConfusion matrix for Decision Tree\n[[ 32  40]\n [ 21 157]]\n\nConfusion matrix for Random Forest\n[[ 27  45]\n [ 13 165]]\n\nConfusion matrix for Logistic Regression\n[[ 24  48]\n [ 21 157]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Looking at the Report, if the scoring metric used to classify a customer is Recall, then Decision Tree would give the best TPR values. This result is different from our statistical analysis as the scoring metric we used was AUC which showed that RF is the best classifier.\nIf we used F1 score as the scoring metric, we again would see that DT comes on top, closely followed by Random Forest classifier."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## 8. Limitations "
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}